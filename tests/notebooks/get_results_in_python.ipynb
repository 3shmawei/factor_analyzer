{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from factor_analyzer import (FactorAnalyzer,\n",
    "                             calculate_bartlett_sphericity,\n",
    "                             calculate_kaiser_meyer_olkin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_dir = '../expected'\n",
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_analysis(top_dir, test_name, factors, method, rotation):\n",
    "    \"\"\"\n",
    "    Use the `FactorAnalyzer()` class to perform the factor analysis\n",
    "    and return a dictionary with relevant results for given scenario.\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = os.path.join(top_dir, test_name + '.csv')\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    rotation = None if rotation == 'none' else rotation\n",
    "    method = {'uls': 'minres'}.get(method, method)\n",
    "\n",
    "    fa = FactorAnalyzer()\n",
    "    fa.analyze(data, factors, method=method, rotation=rotation)\n",
    "    \n",
    "    evalues, values = fa.get_eigenvalues()\n",
    "\n",
    "    return {'value': values,\n",
    "            'evalues': evalues,\n",
    "            'loading': fa.loadings,\n",
    "            'uniquenesses': fa.get_uniqueness(),\n",
    "            'communalities': fa.get_communalities()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_r_output(top_dir, test_name, factors, method, rotation):\n",
    "    \"\"\"\n",
    "    Get the R output for the given scenario.\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    for output_type in ['value',\n",
    "                        'evalues',\n",
    "                        'loading',\n",
    "                        'uniquenesses',\n",
    "                        'communalities']:\n",
    "        \n",
    "        filename = '{}_{}_{}_{}_{}.csv'.format(output_type,\n",
    "                                               method,\n",
    "                                               rotation,\n",
    "                                               factors,\n",
    "                                               test_name)\n",
    "\n",
    "        filename = os.path.join(top_dir, test_name, filename)\n",
    "        \n",
    "        data = pd.read_csv(filename)\n",
    "        output[output_type] = data\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # check for possible index column\n",
    "    possible_index = [col for col in data.columns if 'Unnamed' in col]\n",
    "    \n",
    "    # get numeric columns\n",
    "    numeric_cols = [col for col in data.dtypes[data.dtypes != 'object'].index.values\n",
    "                    if col not in possible_index]\n",
    "    \n",
    "    # take absolute value\n",
    "    data[numeric_cols] = data[numeric_cols].abs()\n",
    "\n",
    "    # set index, if \n",
    "    if len(possible_index) == 1:\n",
    "        data.set_index(possible_index[0], inplace=True)\n",
    "    \n",
    "    # sort the values\n",
    "    data = data[data.abs().sum().sort_values(ascending=False).index.values]\n",
    "\n",
    "    # update index name and column names\n",
    "    data.index.name = ''\n",
    "    data.columns = ['col{}'.format(i) for i in range(1, data.shape[1] + 1)]\n",
    "    return data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_close(data1, data2):\n",
    "    \"\"\"\n",
    "    Check to make sure all values are close.\n",
    "    \"\"\"\n",
    "    data1 = normalize(data1)\n",
    "    data2 = normalize(data2)\n",
    "    \n",
    "    assert data1.shape == data2.shape\n",
    "    \n",
    "    arr = np.empty(shape=data1.shape, dtype=bool)\n",
    "    for i in range(data1.shape[0]):\n",
    "        for j in range(data2.shape[1]):\n",
    "            check = math.isclose(data1.iloc[i, j],\n",
    "                                 data2.iloc[i, j],\n",
    "                                 rel_tol=0,\n",
    "                                 abs_tol=0.1)\n",
    "            arr[i, j] = check\n",
    "    return arr.sum(None) / arr.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_all(data_dir,\n",
    "              expected_dir,\n",
    "              test_name,\n",
    "              factors,\n",
    "              method,\n",
    "              rotation):\n",
    "    \"\"\"\n",
    "    Check all results for given scenario\n",
    "    \"\"\"\n",
    "    results1 = get_r_output(expected_dir, test_name, factors, method, rotation)\n",
    "    results2 = do_analysis(data_dir, test_name, factors, method, rotation)\n",
    "    \n",
    "    for output_type in ['value',\n",
    "                        'evalues',\n",
    "                        'loading',\n",
    "                        'uniquenesses',\n",
    "                        'communalities']:\n",
    "\n",
    "        data1 = results1[output_type]\n",
    "        data2 = results2[output_type]\n",
    "\n",
    "        yield check_close(data1, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_output(data_dir,\n",
    "                expected_dir,\n",
    "                test_name,\n",
    "                factors,\n",
    "                method,\n",
    "                rotation):\n",
    "\n",
    "    results1 = get_r_output(expected_dir, test_name, factors, method, rotation)\n",
    "    results2 = do_analysis(data_dir, test_name, factors, method, rotation)\n",
    "    \n",
    "    for output_type in ['value',\n",
    "                        'evalues',\n",
    "                        'loading',\n",
    "                        'uniquenesses',\n",
    "                        'communalities']:\n",
    "\n",
    "        data1 = results1[output_type]\n",
    "        data2 = results2[output_type]\n",
    "\n",
    "        data1 = normalize(data1)\n",
    "        data2 = normalize(data2)\n",
    "        \n",
    "        print(output_type)\n",
    "        print(data1)\n",
    "        print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "view_output(data_dir,\n",
    "          expected_dir,\n",
    "         'test01',\n",
    "          2,\n",
    "         'uls',\n",
    "         'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
