{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import isclose\n",
    "\n",
    "sys.path.append('..')\n",
    "from factor_analyzer.factor_analyzer import FactorAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPECTED_DIR = '../tests/expected'\n",
    "DATA_DIR = '../tests/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_analysis(data, factors, method, rotation):\n",
    "    \"\"\"\n",
    "    Use the `FactorAnalyzer()` class to perform the factor analysis\n",
    "    and return a dictionary with relevant results.\n",
    "    \"\"\"\n",
    "    rotation = None if rotation == 'none' else rotation\n",
    "\n",
    "    fa = FactorAnalyzer(factors)\n",
    "    fa.analyze(data, method=method, rotation=rotation)\n",
    "\n",
    "    data = fa.loadings\n",
    "    data = data[data.abs().sum().sort_values(ascending=False).index.values]\n",
    "    return data\n",
    "\n",
    "def get_data_by_type(filename, factors, method, rotation, filetype='loadings'):\n",
    "    \"\"\"\n",
    "    Get the R output data by file type (e.g. 'loadings' or 'commonalities').\n",
    "    \"\"\"\n",
    "\n",
    "    subdir, _ = os.path.splitext(filename)\n",
    "\n",
    "    new_file_name = '_'.join([filetype, method, rotation, str(factors), subdir + '.csv'])\n",
    "    new_file_name = os.path.join(EXPECTED_DIR, subdir, new_file_name)\n",
    "\n",
    "    data = pd.read_csv(new_file_name)\n",
    "    data.set_index(data.columns.values[0], inplace=True)\n",
    "    data.columns = ['RFactor{}'.format(num)for num in range(1, data.shape[1] + 1)]\n",
    "    data = data[data.abs().sum().sort_values(ascending=False).index.values]\n",
    "    del data.index.name\n",
    "    return data\n",
    "\n",
    "def check_agreement(df1, df2, abs_tol=1e-04, rel_tol=0):\n",
    "\n",
    "    assert df1.shape == df2.shape\n",
    "\n",
    "    df1 = df1.abs()\n",
    "    df2 = df2.abs()\n",
    "    \n",
    "    result = []\n",
    "    for i in range(df1.shape[0]):\n",
    "        for j in range(df1.shape[1]):\n",
    "            result.append(isclose(df1.iloc[i, j], df2.iloc[i, j], abs_tol=abs_tol, rel_tol=0))\n",
    "    return round((sum(result) / len(result)) * 100, 7)\n",
    "\n",
    "def do_comparison(factors=3, method='minres', rotation='none'):\n",
    "    \n",
    "    if rotation == 'none':\n",
    "        save_rotation = 'unrotated'\n",
    "    else:\n",
    "        save_rotation = rotation\n",
    "    \n",
    "    tests = ['test{}.csv'.format(str(i).zfill(2)) for i in range(1, 11)]\n",
    "    \n",
    "    precisions = []\n",
    "    columns = []\n",
    "    sizes = None\n",
    "    \n",
    "    for precision in [1e-4, 1e-3]:\n",
    "\n",
    "        data_size = []\n",
    "        test_with_precision = []\n",
    "        for test in tests:\n",
    "            \n",
    "            filename = os.path.join(DATA_DIR, test)\n",
    "            data = pd.read_csv(filename)\n",
    "\n",
    "            data_p = do_analysis(data, factors, method, rotation)\n",
    "            data_r = get_data_by_type(test, factors, method, rotation)\n",
    "\n",
    "            test_with_precision.append(check_agreement(data_p, data_r, precision))\n",
    "            \n",
    "            size = data.shape[0]\n",
    "            data_size.append(size)\n",
    "        \n",
    "        columns.append((save_rotation.title(), '{0:.4f}'.format(precision)))\n",
    "        precisions.append(test_with_precision)\n",
    "        sizes = data_size\n",
    "        \n",
    "    columns = pd.MultiIndex.from_tuples(columns, names=['Rotation', 'Relative Tolerance'])\n",
    "\n",
    "\n",
    "    results = pd.DataFrame(np.array(precisions).T, columns=columns)\n",
    "    results['Dataset'] = ['{}'.format(i) for i in range(1, len(tests) + 1)]\n",
    "    results.set_index('Dataset', inplace=True)\n",
    "    results = results[list(reversed(results.columns.values))]\n",
    "    return results.round(2), sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comparison_to_latex():\n",
    "    result = []\n",
    "    for method in ['minres', 'ml']:\n",
    "        for factors in [2, 3]:\n",
    "            \n",
    "            frames = []\n",
    "            all_sizes = None\n",
    "            for rotation in ['none', 'varimax', 'promax']:\n",
    "            \n",
    "                compare, sizes = do_comparison(factors, method, rotation)\n",
    "                frames.append(compare)\n",
    "                all_sizes = sizes\n",
    "\n",
    "            method_name = {'minres': 'ULS', 'ml': 'MLE'}[method]\n",
    "            combined = pd.concat(frames, axis=1)\n",
    "            combined['N'] = sizes\n",
    "            latex_combined = combined.to_latex(multicolumn_format='c')\n",
    "            latex = ['\\\\begin{{table}}[H]\\n\\caption{{Match Rates (\\%), '\n",
    "                     '{} Method, {} Factors}}\\n'.format(method_name, factors),\n",
    "                     latex_combined,\n",
    "                     '\\end{table}']\n",
    "            latex = ''.join(latex)\n",
    "            result.append(latex)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\caption{Match Rates (\\%), ULS Method, 2 Factors}\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "Rotation & \\multicolumn{2}{c}{Unrotated} & \\multicolumn{2}{c}{Varimax} & \\multicolumn{2}{c}{Promax} &       N \\\\\n",
      "Relative Tolerance &    0.0010 & 0.0001 &  0.0010 & 0.0001 & 0.0010 & \\multicolumn{2}{c}{0.0001} \\\\\n",
      "Dataset &           &        &         &        &        &        &         \\\\\n",
      "\\midrule\n",
      "1       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     405 \\\\\n",
      "2       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &    1678 \\\\\n",
      "3       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     175 \\\\\n",
      "4       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     496 \\\\\n",
      "5       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &   42000 \\\\\n",
      "6       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     459 \\\\\n",
      "7       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &    2571 \\\\\n",
      "8       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     189 \\\\\n",
      "9       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     506 \\\\\n",
      "10      &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &  100000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\\begin{table}[H]\n",
      "\\caption{Match Rates (\\%), ULS Method, 3 Factors}\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "Rotation & \\multicolumn{2}{c}{Unrotated} & \\multicolumn{2}{c}{Varimax} & \\multicolumn{2}{c}{Promax} &       N \\\\\n",
      "Relative Tolerance &    0.0010 &  0.0001 &  0.0010 &  0.0001 & 0.0010 & \\multicolumn{2}{c}{0.0001} \\\\\n",
      "Dataset &           &         &         &         &        &         &         \\\\\n",
      "\\midrule\n",
      "1       &     100.0 &  100.00 &   100.0 &  100.00 &  100.0 &  100.00 &     405 \\\\\n",
      "2       &     100.0 &  100.00 &   100.0 &  100.00 &  100.0 &  100.00 &    1678 \\\\\n",
      "3       &     100.0 &   83.33 &   100.0 &  100.00 &  100.0 &  100.00 &     175 \\\\\n",
      "4       &     100.0 &  100.00 &   100.0 &  100.00 &  100.0 &  100.00 &     496 \\\\\n",
      "5       &     100.0 &   80.00 &   100.0 &  100.00 &  100.0 &  100.00 &   42000 \\\\\n",
      "6       &     100.0 &  100.00 &   100.0 &  100.00 &  100.0 &  100.00 &     459 \\\\\n",
      "7       &     100.0 &  100.00 &   100.0 &  100.00 &  100.0 &  100.00 &    2571 \\\\\n",
      "8       &     100.0 &  100.00 &   100.0 &  100.00 &  100.0 &  100.00 &     189 \\\\\n",
      "9       &     100.0 &  100.00 &   100.0 &  100.00 &  100.0 &  100.00 &     506 \\\\\n",
      "10      &     100.0 &   96.67 &   100.0 &   96.67 &  100.0 &   93.33 &  100000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\\begin{table}[H]\n",
      "\\caption{Match Rates (\\%), MLE Method, 2 Factors}\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "Rotation & \\multicolumn{2}{c}{Unrotated} & \\multicolumn{2}{c}{Varimax} & \\multicolumn{2}{c}{Promax} &       N \\\\\n",
      "Relative Tolerance &    0.0010 & 0.0001 &  0.0010 & 0.0001 & 0.0010 & \\multicolumn{2}{c}{0.0001} \\\\\n",
      "Dataset &           &        &         &        &        &        &         \\\\\n",
      "\\midrule\n",
      "1       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     405 \\\\\n",
      "2       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &    1678 \\\\\n",
      "3       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     175 \\\\\n",
      "4       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     496 \\\\\n",
      "5       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &   42000 \\\\\n",
      "6       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     459 \\\\\n",
      "7       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &    2571 \\\\\n",
      "8       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     189 \\\\\n",
      "9       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     506 \\\\\n",
      "10      &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &  100000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\\begin{table}[H]\n",
      "\\caption{Match Rates (\\%), MLE Method, 3 Factors}\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "Rotation & \\multicolumn{2}{c}{Unrotated} & \\multicolumn{2}{c}{Varimax} & \\multicolumn{2}{c}{Promax} &       N \\\\\n",
      "Relative Tolerance &    0.0010 & 0.0001 &  0.0010 & 0.0001 & 0.0010 & \\multicolumn{2}{c}{0.0001} \\\\\n",
      "Dataset &           &        &         &        &        &        &         \\\\\n",
      "\\midrule\n",
      "1       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     405 \\\\\n",
      "2       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &    1678 \\\\\n",
      "3       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     175 \\\\\n",
      "4       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     496 \\\\\n",
      "5       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &   42000 \\\\\n",
      "6       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     459 \\\\\n",
      "7       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &    2571 \\\\\n",
      "8       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     189 \\\\\n",
      "9       &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &     506 \\\\\n",
      "10      &     100.0 &  100.0 &   100.0 &  100.0 &  100.0 &  100.0 &  100000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "for latex in get_comparison_to_latex():\n",
    "    print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('../tests/data', 'test10.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa.analyze(data, method='minres', rotation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa.loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
